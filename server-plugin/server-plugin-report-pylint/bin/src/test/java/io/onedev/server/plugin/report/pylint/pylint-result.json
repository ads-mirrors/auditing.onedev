[
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "FTRecipeInterface.load_checkpoint",
        "line": 32,
        "column": 8,
        "endLine": 32,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "FTRecipeInterface.setup",
        "line": 39,
        "column": 8,
        "endLine": 39,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "FTRecipeInterface.train",
        "line": 46,
        "column": 8,
        "endLine": 46,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "FTRecipeInterface.save_checkpoint",
        "line": 54,
        "column": 8,
        "endLine": 54,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "FTRecipeInterface.cleanup",
        "line": 60,
        "column": 8,
        "endLine": 60,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "EvalRecipeInterface.load_checkpoint",
        "line": 75,
        "column": 8,
        "endLine": 75,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "EvalRecipeInterface.setup",
        "line": 81,
        "column": 8,
        "endLine": 81,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.recipe_interfaces",
        "obj": "EvalRecipeInterface.evaluate",
        "line": 87,
        "column": 8,
        "endLine": 87,
        "endColumn": 11,
        "path": "torchtune/recipe_interfaces.py",
        "symbol": "unnecessary-ellipsis",
        "message": "Unnecessary ellipsis constant",
        "message-id": "W2301"
    },
    {
        "type": "warning",
        "module": "torchtune.config._errors",
        "obj": "InstantiationError",
        "line": 15,
        "column": 4,
        "endLine": 15,
        "endColumn": 8,
        "path": "torchtune/config/_errors.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.config._instantiate",
        "obj": "_instantiate_node",
        "line": 28,
        "column": 4,
        "endLine": 36,
        "endColumn": 9,
        "path": "torchtune/config/_instantiate.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.config._instantiate",
        "obj": "instantiate",
        "line": 93,
        "column": 4,
        "endLine": 93,
        "endColumn": 25,
        "path": "torchtune/config/_instantiate.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _set_flag of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.config._instantiate",
        "obj": "instantiate",
        "line": 96,
        "column": 4,
        "endLine": 96,
        "endColumn": 27,
        "path": "torchtune/config/_instantiate.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _set_parent of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.config._instantiate",
        "obj": "instantiate",
        "line": 96,
        "column": 28,
        "endLine": 96,
        "endColumn": 46,
        "path": "torchtune/config/_instantiate.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _get_parent of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.config._parse",
        "obj": "parse.wrapper",
        "line": 90,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/config/_parse.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.config._parse",
        "obj": "parse.wrapper",
        "line": 90,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/config/_parse.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.config._validate",
        "obj": "validate",
        "line": 26,
        "column": 8,
        "endLine": 26,
        "endColumn": 12,
        "path": "torchtune/config/_validate.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'node'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.config._utils",
        "obj": "_get_component_from_path",
        "line": 69,
        "column": 12,
        "endLine": 69,
        "endColumn": 46,
        "path": "torchtune/config/_utils.py",
        "symbol": "unnecessary-comprehension",
        "message": "Unnecessary use of a comprehension, use list(path.split('.')) instead.",
        "message-id": "R1721"
    },
    {
        "type": "convention",
        "module": "torchtune.config._utils",
        "obj": "_get_component_from_path",
        "line": 72,
        "column": 11,
        "endLine": 72,
        "endColumn": 24,
        "path": "torchtune/config/_utils.py",
        "symbol": "use-implicit-booleaness-not-len",
        "message": "Do not use `len(SEQUENCE)` without comparison to determine if a sequence is empty",
        "message-id": "C1802"
    },
    {
        "type": "refactor",
        "module": "torchtune.config._utils",
        "obj": "_get_prompt_template",
        "line": 243,
        "column": 4,
        "endLine": 250,
        "endColumn": 9,
        "path": "torchtune/config/_utils.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"elif\" after \"return\", remove the leading \"el\" from \"elif\"",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training.memory",
        "obj": "log_memory_stats",
        "line": 237,
        "column": 4,
        "endLine": 242,
        "endColumn": 5,
        "path": "torchtune/training/memory.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "convention",
        "module": "torchtune.training.activations",
        "obj": "",
        "line": 40,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/activations.py",
        "symbol": "superfluous-parens",
        "message": "Unnecessary parens after 'not' keyword",
        "message-id": "C0325"
    },
    {
        "type": "convention",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 19,
        "column": 0,
        "endLine": 19,
        "endColumn": 22,
        "path": "torchtune/training/activations.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 21,
        "column": 4,
        "endLine": 63,
        "endColumn": 9,
        "path": "torchtune/training/activations.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"elif\" after \"return\", remove the leading \"el\" from \"elif\"",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 32,
        "column": 8,
        "endLine": 37,
        "endColumn": 11,
        "path": "torchtune/training/activations.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "convention",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 40,
        "column": 11,
        "endLine": 40,
        "endColumn": 35,
        "path": "torchtune/training/activations.py",
        "symbol": "unnecessary-negation",
        "message": "Consider changing \"not every_x_layer >= 0\" to \"every_x_layer < 0\"",
        "message-id": "C0117"
    },
    {
        "type": "error",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 47,
        "column": 8,
        "endLine": 47,
        "endColumn": 33,
        "path": "torchtune/training/activations.py",
        "symbol": "no-member",
        "message": "Function 'checkpoint_wrapper' has no '_count' member",
        "message-id": "E1101"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 48,
        "column": 8,
        "endLine": 58,
        "endColumn": 25,
        "path": "torchtune/training/activations.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 48,
        "column": 32,
        "endLine": 48,
        "endColumn": 57,
        "path": "torchtune/training/activations.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _count of a client class",
        "message-id": "W0212"
    },
    {
        "type": "error",
        "module": "torchtune.training.activations",
        "obj": "checkpoint_wrapper",
        "line": 48,
        "column": 32,
        "endLine": 48,
        "endColumn": 57,
        "path": "torchtune/training/activations.py",
        "symbol": "no-member",
        "message": "Function 'checkpoint_wrapper' has no '_count' member",
        "message-id": "E1101"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "",
        "line": 320,
        "column": 13,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_distributed.py",
        "symbol": "fixme",
        "message": "TODO: change to from_local API (need to add view support for NF4)",
        "message-id": "W0511"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "_broadcast_tensor",
        "line": 106,
        "column": 4,
        "endLine": 113,
        "endColumn": 21,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "init_distributed",
        "line": 128,
        "column": 4,
        "endLine": 134,
        "endColumn": 20,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "set_torch_num_threads",
        "line": 150,
        "column": 4,
        "endLine": 150,
        "endColumn": 74,
        "path": "torchtune/training/_distributed.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "get_world_size_and_rank",
        "line": 160,
        "column": 4,
        "endLine": 163,
        "endColumn": 19,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "_dummy_reset_params",
        "line": 199,
        "column": 24,
        "endLine": 199,
        "endColumn": 36,
        "path": "torchtune/training/_distributed.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'x'",
        "message-id": "W0613"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 234,
        "column": 12,
        "endLine": 234,
        "endColumn": 63,
        "path": "torchtune/training/_distributed.py",
        "symbol": "assignment-from-none",
        "message": "Assigning result of a function call, where the function returns None",
        "message-id": "E1128"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 234,
        "column": 33,
        "endLine": 234,
        "endColumn": 63,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'type' in function call",
        "message-id": "E1120"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 238,
        "column": 11,
        "endLine": 238,
        "endColumn": 65,
        "path": "torchtune/training/_distributed.py",
        "symbol": "consider-merging-isinstance",
        "message": "Consider merging these isinstance calls to isinstance(v, (DoRALinear, LoRALinear))",
        "message-id": "R1701"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 239,
        "column": 12,
        "endLine": 239,
        "endColumn": 77,
        "path": "torchtune/training/_distributed.py",
        "symbol": "assignment-from-no-return",
        "message": "Assigning result of a function call, where the function has no return",
        "message-id": "E1111"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 239,
        "column": 40,
        "endLine": 239,
        "endColumn": 77,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'type' in function call",
        "message-id": "E1120"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 240,
        "column": 12,
        "endLine": 240,
        "endColumn": 77,
        "path": "torchtune/training/_distributed.py",
        "symbol": "assignment-from-no-return",
        "message": "Assigning result of a function call, where the function has no return",
        "message-id": "E1111"
    },
    {
        "type": "error",
        "module": "torchtune.training._distributed",
        "obj": "prepare_model_for_fsdp_with_meta_device",
        "line": 240,
        "column": 40,
        "endLine": 240,
        "endColumn": 77,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'type' in function call",
        "message-id": "E1120"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "lora_fsdp_wrap_policy.lora_wrap_fsdp",
        "line": 266,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_distributed.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_model_state_dict",
        "line": 282,
        "column": 0,
        "endLine": 282,
        "endColumn": 35,
        "path": "torchtune/training/_distributed.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_model_state_dict",
        "line": 302,
        "column": 22,
        "endLine": 302,
        "endColumn": 54,
        "path": "torchtune/training/_distributed.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _local_tensor of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_model_state_dict",
        "line": 286,
        "column": 4,
        "endLine": 286,
        "endColumn": 22,
        "path": "torchtune/training/_distributed.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'is_rank_zero'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "get_full_model_state_dict",
        "line": 357,
        "column": 19,
        "endLine": 357,
        "endColumn": 38,
        "path": "torchtune/training/_distributed.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _local_tensor of a client class",
        "message-id": "W0212"
    },
    {
        "type": "convention",
        "module": "torchtune.training._distributed",
        "obj": "get_full_model_state_dict",
        "line": 360,
        "column": 8,
        "endLine": 360,
        "endColumn": 77,
        "path": "torchtune/training/_distributed.py",
        "symbol": "import-outside-toplevel",
        "message": "Import outside toplevel (torch.distributed._composable.fsdp.fully_shard.FSDPModule)",
        "message-id": "C0415"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "get_full_model_state_dict",
        "line": 346,
        "column": 0,
        "endLine": 346,
        "endColumn": 29,
        "path": "torchtune/training/_distributed.py",
        "symbol": "too-many-branches",
        "message": "Too many branches (14/12)",
        "message-id": "R0912"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "get_full_optimizer_state_dict",
        "line": 434,
        "column": 4,
        "endLine": 440,
        "endColumn": 17,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_optimizer_state_dict",
        "line": 443,
        "column": 0,
        "endLine": 443,
        "endColumn": 39,
        "path": "torchtune/training/_distributed.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (19/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_optimizer_state_dict",
        "line": 452,
        "column": 4,
        "endLine": 452,
        "endColumn": 10,
        "path": "torchtune/training/_distributed.py",
        "symbol": "invalid-name",
        "message": "Variable name \"PARAMS\" doesn't conform to snake_case naming style",
        "message-id": "C0103"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "load_from_full_optimizer_state_dict",
        "line": 446,
        "column": 4,
        "endLine": 446,
        "endColumn": 24,
        "path": "torchtune/training/_distributed.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'device'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "get_full_finetune_fsdp_wrap_policy",
        "line": 512,
        "column": 4,
        "endLine": 515,
        "endColumn": 48,
        "path": "torchtune/training/_distributed.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "_memory_efficient_wrap_policy.llama3_wrap",
        "line": 537,
        "column": 12,
        "endLine": 537,
        "endColumn": 31,
        "path": "torchtune/training/_distributed.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _wrap of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.training._distributed",
        "obj": "_memory_efficient_wrap_policy.llama3_wrap",
        "line": 534,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_distributed.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._distributed",
        "obj": "shard_model",
        "line": 583,
        "column": 11,
        "endLine": 583,
        "endColumn": 79,
        "path": "torchtune/training/_distributed.py",
        "symbol": "use-a-generator",
        "message": "Use a generator instead 'any(shard_condition(n, m) for shard_condition in shard_conditions)'",
        "message-id": "R1729"
    },
    {
        "type": "warning",
        "module": "torchtune.training.seed",
        "obj": "set_seed",
        "line": 60,
        "column": 8,
        "endLine": 62,
        "endColumn": 9,
        "path": "torchtune/training/seed.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.seed",
        "obj": "set_seed",
        "line": 69,
        "column": 8,
        "endLine": 69,
        "endColumn": 71,
        "path": "torchtune/training/seed.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "MetricLoggerInterface.log",
        "line": 43,
        "column": 8,
        "endLine": 43,
        "endColumn": 12,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "MetricLoggerInterface.log_config",
        "line": 51,
        "column": 8,
        "endLine": 51,
        "endColumn": 12,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "MetricLoggerInterface.log_dict",
        "line": 60,
        "column": 8,
        "endLine": 60,
        "endColumn": 12,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "MetricLoggerInterface.close",
        "line": 67,
        "column": 8,
        "endLine": 67,
        "endColumn": 12,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "DiskLogger.__init__",
        "line": 93,
        "column": 21,
        "endLine": 93,
        "endColumn": 47,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.metric_logging",
        "obj": "DiskLogger.__init__",
        "line": 93,
        "column": 21,
        "endLine": 93,
        "endColumn": 47,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "consider-using-with",
        "message": "Consider using 'with' for resource-allocating operations",
        "message-id": "R1732"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "DiskLogger.__init__",
        "line": 86,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "convention",
        "module": "torchtune.training.metric_logging",
        "obj": "DiskLogger.path_to_log_file",
        "line": 96,
        "column": 4,
        "endLine": 96,
        "endColumn": 24,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.training.metric_logging",
        "obj": "WandBLogger.__init__",
        "line": 176,
        "column": 12,
        "endLine": 176,
        "endColumn": 24,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "import-outside-toplevel",
        "message": "Import outside toplevel (wandb)",
        "message-id": "C0415"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "WandBLogger.__init__",
        "line": 191,
        "column": 12,
        "endLine": 191,
        "endColumn": 15,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'run'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "WandBLogger.log_config",
        "line": 237,
        "column": 19,
        "endLine": 237,
        "endColumn": 28,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "broad-exception-caught",
        "message": "Catching too general exception Exception",
        "message-id": "W0718"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "WandBLogger.log_config",
        "line": 232,
        "column": 16,
        "endLine": 232,
        "endColumn": 77,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "WandBLogger.log_config",
        "line": 238,
        "column": 16,
        "endLine": 241,
        "endColumn": 17,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "convention",
        "module": "torchtune.training.metric_logging",
        "obj": "TensorBoardLogger.__init__",
        "line": 288,
        "column": 8,
        "endLine": 288,
        "endColumn": 57,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "import-outside-toplevel",
        "message": "Import outside toplevel (torch.utils.tensorboard.SummaryWriter)",
        "message-id": "C0415"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "TensorBoardLogger.__init__",
        "line": 287,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.metric_logging",
        "obj": "CometLogger.__init__",
        "line": 370,
        "column": 4,
        "endLine": 370,
        "endColumn": 16,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.training.metric_logging",
        "obj": "CometLogger.__init__",
        "line": 384,
        "column": 12,
        "endLine": 384,
        "endColumn": 27,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "import-outside-toplevel",
        "message": "Import outside toplevel (comet_ml)",
        "message-id": "C0415"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "CometLogger.log_config",
        "line": 427,
        "column": 19,
        "endLine": 427,
        "endColumn": 28,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "broad-exception-caught",
        "message": "Catching too general exception Exception",
        "message-id": "W0718"
    },
    {
        "type": "warning",
        "module": "torchtune.training.metric_logging",
        "obj": "CometLogger.log_config",
        "line": 428,
        "column": 16,
        "endLine": 428,
        "endColumn": 75,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.metric_logging",
        "obj": "CometLogger.log_config",
        "line": 419,
        "column": 4,
        "endLine": 419,
        "endColumn": 18,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "useless-return",
        "message": "Useless return at end of function or method",
        "message-id": "R1711"
    },
    {
        "type": "convention",
        "module": "torchtune.training.metric_logging",
        "obj": "",
        "line": 20,
        "column": 0,
        "endLine": 20,
        "endColumn": 38,
        "path": "torchtune/training/metric_logging.py",
        "symbol": "wrong-import-order",
        "message": "third party import \"typing_extensions.Protocol\" should be placed before first party imports \"torchtune.training._distributed.get_world_size_and_rank\", \"torchtune.utils.get_logger\" ",
        "message-id": "C0411"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "",
        "line": 135,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_profiler.py",
        "symbol": "fixme",
        "message": "TODO: Is this necessary?",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 95,
        "column": 8,
        "endLine": 95,
        "endColumn": 59,
        "path": "torchtune/training/_profiler.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 106,
        "column": 8,
        "endLine": 106,
        "endColumn": 86,
        "path": "torchtune/training/_profiler.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 115,
        "column": 19,
        "endLine": 115,
        "endColumn": 28,
        "path": "torchtune/training/_profiler.py",
        "symbol": "broad-exception-caught",
        "message": "Catching too general exception Exception",
        "message-id": "W0718"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 116,
        "column": 16,
        "endLine": 116,
        "endColumn": 67,
        "path": "torchtune/training/_profiler.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 116,
        "column": 16,
        "endLine": 116,
        "endColumn": 67,
        "path": "torchtune/training/_profiler.py",
        "symbol": "deprecated-method",
        "message": "Using deprecated method warn()",
        "message-id": "W4902"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 116,
        "column": 16,
        "endLine": 116,
        "endColumn": 67,
        "path": "torchtune/training/_profiler.py",
        "symbol": "deprecated-method",
        "message": "Using deprecated method warn()",
        "message-id": "W4902"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 118,
        "column": 12,
        "endLine": 118,
        "endColumn": 44,
        "path": "torchtune/training/_profiler.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _dump_snapshot of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 130,
        "column": 9,
        "endLine": 130,
        "endColumn": 67,
        "path": "torchtune/training/_profiler.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "warning",
        "module": "torchtune.training._profiler",
        "obj": "trace_handler",
        "line": 133,
        "column": 8,
        "endLine": 133,
        "endColumn": 65,
        "path": "torchtune/training/_profiler.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "DummyProfiler.start",
        "line": 169,
        "column": 4,
        "endLine": 169,
        "endColumn": 13,
        "path": "torchtune/training/_profiler.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "DummyProfiler.stop",
        "line": 172,
        "column": 4,
        "endLine": 172,
        "endColumn": 12,
        "path": "torchtune/training/_profiler.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "DummyProfiler.step",
        "line": 175,
        "column": 4,
        "endLine": 175,
        "endColumn": 12,
        "path": "torchtune/training/_profiler.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 179,
        "column": 0,
        "endLine": 179,
        "endColumn": 24,
        "path": "torchtune/training/_profiler.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 179,
        "column": 0,
        "endLine": 179,
        "endColumn": 24,
        "path": "torchtune/training/_profiler.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (22/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 299,
        "column": 12,
        "endLine": 299,
        "endColumn": 60,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-using-f-string",
        "message": "Formatting a regular string which could be an f-string",
        "message-id": "C0209"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 300,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-using-dict-items",
        "message": "Consider iterating with .items()",
        "message-id": "C0206"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 300,
        "column": 63,
        "endLine": 300,
        "endColumn": 83,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-iterating-dictionary",
        "message": "Consider iterating the dictionary directly instead of calling .keys()",
        "message-id": "C0201"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 310,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-using-dict-items",
        "message": "Consider iterating with .items()",
        "message-id": "C0206"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 310,
        "column": 35,
        "endLine": 310,
        "endColumn": 55,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-iterating-dictionary",
        "message": "Consider iterating the dictionary directly instead of calling .keys()",
        "message-id": "C0201"
    },
    {
        "type": "convention",
        "module": "torchtune.training._profiler",
        "obj": "setup_torch_profiler",
        "line": 315,
        "column": 16,
        "endLine": 315,
        "endColumn": 79,
        "path": "torchtune/training/_profiler.py",
        "symbol": "consider-using-f-string",
        "message": "Formatting a regular string which could be an f-string",
        "message-id": "C0209"
    },
    {
        "type": "convention",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "_CheckpointerInterface.load_checkpoint",
        "line": 94,
        "column": 4,
        "endLine": 94,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "_CheckpointerInterface.save_checkpoint",
        "line": 97,
        "column": 4,
        "endLine": 97,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.__init__",
        "line": 128,
        "column": 4,
        "endLine": 128,
        "endColumn": 16,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.load_checkpoint",
        "line": 174,
        "column": 4,
        "endLine": 174,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelTorchTuneCheckpointer.load_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 211,
        "column": 4,
        "endLine": 211,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Number of parameters was 3 in '_CheckpointerInterface.save_checkpoint' and is now 5 in overriding 'FullModelTorchTuneCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 211,
        "column": 4,
        "endLine": 211,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelTorchTuneCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 256,
        "column": 12,
        "endLine": 260,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 267,
        "column": 12,
        "endLine": 271,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 284,
        "column": 12,
        "endLine": 288,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelTorchTuneCheckpointer.save_checkpoint",
        "line": 292,
        "column": 16,
        "endLine": 296,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer",
        "line": 304,
        "column": 0,
        "endLine": 304,
        "endColumn": 29,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (10/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.__init__",
        "line": 336,
        "column": 4,
        "endLine": 336,
        "endColumn": 16,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (9/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.__init__",
        "line": 367,
        "column": 12,
        "endLine": 367,
        "endColumn": 74,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.load_checkpoint",
        "line": 393,
        "column": 4,
        "endLine": 393,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelHFCheckpointer.load_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 479,
        "column": 4,
        "endLine": 479,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Number of parameters was 3 in '_CheckpointerInterface.save_checkpoint' and is now 5 in overriding 'FullModelHFCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 479,
        "column": 4,
        "endLine": 479,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelHFCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 557,
        "column": 16,
        "endLine": 561,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 570,
        "column": 12,
        "endLine": 574,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 594,
        "column": 16,
        "endLine": 598,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 616,
        "column": 21,
        "endLine": 616,
        "endColumn": 43,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 618,
        "column": 16,
        "endLine": 622,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 632,
        "column": 12,
        "endLine": 636,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 640,
        "column": 16,
        "endLine": 644,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 479,
        "column": 4,
        "endLine": 479,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-branches",
        "message": "Too many branches (21/12)",
        "message-id": "R0912"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelHFCheckpointer.save_checkpoint",
        "line": 479,
        "column": 4,
        "endLine": 479,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-statements",
        "message": "Too many statements (58/50)",
        "message-id": "R0915"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.__init__",
        "line": 676,
        "column": 4,
        "endLine": 676,
        "endColumn": 16,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.load_checkpoint",
        "line": 716,
        "column": 4,
        "endLine": 716,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelMetaCheckpointer.load_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 733,
        "column": 4,
        "endLine": 733,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Number of parameters was 3 in '_CheckpointerInterface.save_checkpoint' and is now 5 in overriding 'FullModelMetaCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 733,
        "column": 4,
        "endLine": 733,
        "endColumn": 23,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'FullModelMetaCheckpointer.save_checkpoint' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 768,
        "column": 12,
        "endLine": 772,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 779,
        "column": 12,
        "endLine": 783,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 797,
        "column": 12,
        "endLine": 801,
        "endColumn": 13,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._checkpointer",
        "obj": "FullModelMetaCheckpointer.save_checkpoint",
        "line": 805,
        "column": 16,
        "endLine": 809,
        "endColumn": 17,
        "path": "torchtune/training/checkpointing/_checkpointer.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._utils",
        "obj": "",
        "line": 16,
        "column": 0,
        "endLine": 18,
        "endColumn": 3,
        "path": "torchtune/training/checkpointing/_utils.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.training.checkpointing._utils",
        "obj": "safe_torch_load",
        "line": 122,
        "column": 12,
        "endLine": 122,
        "endColumn": 76,
        "path": "torchtune/training/checkpointing/_utils.py",
        "symbol": "simplifiable-if-expression",
        "message": "The if expression can be replaced with 'bool(test)'",
        "message-id": "R1719"
    },
    {
        "type": "warning",
        "module": "torchtune.training.checkpointing._utils",
        "obj": "save_config",
        "line": 154,
        "column": 13,
        "endLine": 154,
        "endColumn": 33,
        "path": "torchtune/training/checkpointing/_utils.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._alpaca",
        "obj": "AlpacaToMessages",
        "line": 18,
        "column": 0,
        "endLine": 18,
        "endColumn": 22,
        "path": "torchtune/datasets/_alpaca.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._alpaca",
        "obj": "alpaca_dataset",
        "line": 85,
        "column": 0,
        "endLine": 85,
        "endColumn": 18,
        "path": "torchtune/datasets/_alpaca.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._stack_exchange_paired",
        "obj": "StackExchangePairedToMessages",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 35,
        "path": "torchtune/datasets/_stack_exchange_paired.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._hh_rlhf_helpful",
        "obj": "hh_rlhf_helpful_dataset",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 27,
        "path": "torchtune/datasets/_hh_rlhf_helpful.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._grammar",
        "obj": "grammar_dataset",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 19,
        "path": "torchtune/datasets/_grammar.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._chat",
        "obj": "ChatDataset.__init__",
        "line": 73,
        "column": 4,
        "endLine": 73,
        "endColumn": 16,
        "path": "torchtune/datasets/_chat.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._chat",
        "obj": "chat_dataset",
        "line": 114,
        "column": 0,
        "endLine": 114,
        "endColumn": 16,
        "path": "torchtune/datasets/_chat.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.datasets._preference",
        "obj": "",
        "line": 113,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/datasets/_preference.py",
        "symbol": "fixme",
        "message": "TODO: Truncation differs from original DPO repo",
        "message-id": "W0511"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._preference",
        "obj": "PreferenceDataset._prepare_sample",
        "line": 132,
        "column": 25,
        "endLine": 137,
        "endColumn": 9,
        "path": "torchtune/datasets/_preference.py",
        "symbol": "use-dict-literal",
        "message": "Consider using '{\"chosen_input_ids\": chosen_input_ids, \"chosen_labels\": chosen_labels, ... }' instead of a call to 'dict'.",
        "message-id": "R1735"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._slimorca",
        "obj": "slimorca_dataset",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 20,
        "path": "torchtune/datasets/_slimorca.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._wikitext",
        "obj": "wikitext_dataset",
        "line": 19,
        "column": 0,
        "endLine": 19,
        "endColumn": 20,
        "path": "torchtune/datasets/_wikitext.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.datasets._wikitext",
        "obj": "wikitext_dataset",
        "line": 24,
        "column": 4,
        "endLine": 24,
        "endColumn": 16,
        "path": "torchtune/datasets/_wikitext.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'packed'",
        "message-id": "W0613"
    },
    {
        "type": "convention",
        "module": "torchtune.datasets._instruct",
        "obj": "",
        "line": 116,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/datasets/_instruct.py",
        "symbol": "superfluous-parens",
        "message": "Unnecessary parens after '=' keyword",
        "message-id": "C0325"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._instruct",
        "obj": "InstructDataset.__init__",
        "line": 75,
        "column": 4,
        "endLine": 75,
        "endColumn": 16,
        "path": "torchtune/datasets/_instruct.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._instruct",
        "obj": "instruct_dataset",
        "line": 133,
        "column": 0,
        "endLine": 133,
        "endColumn": 20,
        "path": "torchtune/datasets/_instruct.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._text_completion",
        "obj": "TextCompletionDataset.__init__",
        "line": 40,
        "column": 4,
        "endLine": 40,
        "endColumn": 16,
        "path": "torchtune/datasets/_text_completion.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._text_completion",
        "obj": "text_completion_dataset",
        "line": 79,
        "column": 0,
        "endLine": 79,
        "endColumn": 27,
        "path": "torchtune/datasets/_text_completion.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._samsum",
        "obj": "samsum_dataset",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 18,
        "path": "torchtune/datasets/_samsum.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._concat",
        "obj": "ConcatDataset.__getitem__",
        "line": 77,
        "column": 4,
        "endLine": 77,
        "endColumn": 19,
        "path": "torchtune/datasets/_concat.py",
        "symbol": "inconsistent-return-statements",
        "message": "Either all return statements in a function should return an expression, or none of them should.",
        "message-id": "R1710"
    },
    {
        "type": "convention",
        "module": "torchtune.datasets._packed",
        "obj": "",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 9,
        "path": "torchtune/datasets/_packed.py",
        "symbol": "invalid-name",
        "message": "Class name \"PACK_TYPE\" doesn't conform to PascalCase naming style",
        "message-id": "C0103"
    },
    {
        "type": "refactor",
        "module": "torchtune.datasets._packed",
        "obj": "PackedDataset.__init__",
        "line": 86,
        "column": 4,
        "endLine": 86,
        "endColumn": 16,
        "path": "torchtune/datasets/_packed.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.datasets._packed",
        "obj": "",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 21,
        "path": "torchtune/datasets/_packed.py",
        "symbol": "wrong-import-order",
        "message": "third party import \"tqdm.tqdm\" should be placed before first party imports \"torchtune.data.CROSS_ENTROPY_IGNORE_IDX\", \"torchtune.training.get_world_size_and_rank\" ",
        "message-id": "C0411"
    },
    {
        "type": "refactor",
        "module": "torchtune.utils._generation",
        "obj": "generate",
        "line": 64,
        "column": 0,
        "endLine": 64,
        "endColumn": 12,
        "path": "torchtune/utils/_generation.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.utils._generation",
        "obj": "generate",
        "line": 64,
        "column": 0,
        "endLine": 64,
        "endColumn": 12,
        "path": "torchtune/utils/_generation.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.convert_weights",
        "obj": "get_mapped_key",
        "line": 48,
        "column": 0,
        "endLine": 48,
        "endColumn": 18,
        "path": "torchtune/models/convert_weights.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.convert_weights",
        "obj": "get_mapped_key",
        "line": 59,
        "column": 8,
        "endLine": 62,
        "endColumn": 16,
        "path": "torchtune/models/convert_weights.py",
        "symbol": "broad-exception-raised",
        "message": "Raising too general exception: Exception",
        "message-id": "W0719"
    },
    {
        "type": "convention",
        "module": "torchtune.models.convert_weights",
        "obj": "tune_to_peft_adapter_config",
        "line": 231,
        "column": 0,
        "endLine": 231,
        "endColumn": 31,
        "path": "torchtune/models/convert_weights.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.convert_weights",
        "obj": "tune_to_peft_adapter_config",
        "line": 234,
        "column": 11,
        "endLine": 234,
        "endColumn": 80,
        "path": "torchtune/models/convert_weights.py",
        "symbol": "use-a-generator",
        "message": "Use a generator instead 'all(x in adapter_config.keys() for x in _PEFT_CONFIG_EXPECTED_KEYS)'",
        "message-id": "R1729"
    },
    {
        "type": "convention",
        "module": "torchtune.models.convert_weights",
        "obj": "tune_to_peft_adapter_weights",
        "line": 249,
        "column": 0,
        "endLine": 249,
        "endColumn": 32,
        "path": "torchtune/models/convert_weights.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3._model_builders",
        "obj": "",
        "line": 67,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama3/_model_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._model_builders",
        "obj": "",
        "line": 19,
        "column": 0,
        "endLine": 23,
        "endColumn": 3,
        "path": "torchtune/models/llama3/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._model_builders",
        "obj": "lora_llama3_8b",
        "line": 92,
        "column": 0,
        "endLine": 92,
        "endColumn": 18,
        "path": "torchtune/models/llama3/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._model_builders",
        "obj": "lora_llama3_70b",
        "line": 147,
        "column": 0,
        "endLine": 147,
        "endColumn": 19,
        "path": "torchtune/models/llama3/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "",
        "line": 238,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "",
        "line": 29,
        "column": 0,
        "endLine": 39,
        "endColumn": 3,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "llama3",
        "line": 44,
        "column": 0,
        "endLine": 44,
        "endColumn": 10,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "llama3",
        "line": 44,
        "column": 0,
        "endLine": 44,
        "endColumn": 10,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3",
        "line": 134,
        "column": 0,
        "endLine": 134,
        "endColumn": 15,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (18/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3",
        "line": 134,
        "column": 0,
        "endLine": 134,
        "endColumn": 15,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (26/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3",
        "line": 259,
        "column": 8,
        "endLine": 259,
        "endColumn": 39,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3_self_attention",
        "line": 266,
        "column": 0,
        "endLine": 266,
        "endColumn": 30,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3_self_attention",
        "line": 266,
        "column": 0,
        "endLine": 266,
        "endColumn": 30,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3_mlp",
        "line": 405,
        "column": 0,
        "endLine": 405,
        "endColumn": 19,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "lora_llama3_mlp",
        "line": 405,
        "column": 0,
        "endLine": 405,
        "endColumn": 19,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "",
        "line": 8,
        "column": 0,
        "endLine": 8,
        "endColumn": 42,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "unused-import",
        "message": "Unused Literal imported from typing",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._component_builders",
        "obj": "",
        "line": 14,
        "column": 0,
        "endLine": 23,
        "endColumn": 1,
        "path": "torchtune/models/llama3/_component_builders.py",
        "symbol": "unused-import",
        "message": "Unused KVCache imported from torchtune.modules",
        "message-id": "W0611"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3._tokenizer",
        "obj": "Llama3Tokenizer",
        "line": 42,
        "column": 0,
        "endLine": 42,
        "endColumn": 21,
        "path": "torchtune/models/llama3/_tokenizer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (15/7)",
        "message-id": "R0902"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3._tokenizer",
        "obj": "Llama3Tokenizer.base_vocab_size",
        "line": 135,
        "column": 4,
        "endLine": 135,
        "endColumn": 23,
        "path": "torchtune/models/llama3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3._tokenizer",
        "obj": "Llama3Tokenizer.vocab_size",
        "line": 139,
        "column": 4,
        "endLine": 139,
        "endColumn": 18,
        "path": "torchtune/models/llama3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3._tokenizer",
        "obj": "Llama3Tokenizer.encode",
        "line": 142,
        "column": 4,
        "endLine": 142,
        "endColumn": 14,
        "path": "torchtune/models/llama3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3._tokenizer",
        "obj": "Llama3Tokenizer.tokenize_messages",
        "line": 240,
        "column": 4,
        "endLine": 240,
        "endColumn": 25,
        "path": "torchtune/models/llama3/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'Llama3Tokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._model_builders",
        "obj": "",
        "line": 18,
        "column": 0,
        "endLine": 22,
        "endColumn": 3,
        "path": "torchtune/models/llama2/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._model_builders",
        "obj": "lora_llama2_7b",
        "line": 64,
        "column": 0,
        "endLine": 64,
        "endColumn": 18,
        "path": "torchtune/models/llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._model_builders",
        "obj": "lora_llama2_13b",
        "line": 150,
        "column": 0,
        "endLine": 150,
        "endColumn": 19,
        "path": "torchtune/models/llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._model_builders",
        "obj": "lora_llama2_70b",
        "line": 235,
        "column": 0,
        "endLine": 235,
        "endColumn": 19,
        "path": "torchtune/models/llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._model_builders",
        "obj": "lora_llama2_reward_7b",
        "line": 320,
        "column": 0,
        "endLine": 320,
        "endColumn": 25,
        "path": "torchtune/models/llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "",
        "line": 258,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "",
        "line": 288,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "",
        "line": 666,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "",
        "line": 696,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "",
        "line": 27,
        "column": 0,
        "endLine": 37,
        "endColumn": 3,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "llama2",
        "line": 43,
        "column": 0,
        "endLine": 43,
        "endColumn": 10,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "llama2",
        "line": 43,
        "column": 0,
        "endLine": 43,
        "endColumn": 10,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2",
        "line": 152,
        "column": 0,
        "endLine": 152,
        "endColumn": 15,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (17/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2",
        "line": 152,
        "column": 0,
        "endLine": 152,
        "endColumn": 15,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (25/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2",
        "line": 285,
        "column": 8,
        "endLine": 285,
        "endColumn": 39,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_self_attention",
        "line": 298,
        "column": 0,
        "endLine": 298,
        "endColumn": 30,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (11/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_self_attention",
        "line": 298,
        "column": 0,
        "endLine": 298,
        "endColumn": 30,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (19/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_mlp",
        "line": 437,
        "column": 0,
        "endLine": 437,
        "endColumn": 19,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_mlp",
        "line": 437,
        "column": 0,
        "endLine": 437,
        "endColumn": 19,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "llama2_classifier",
        "line": 482,
        "column": 0,
        "endLine": 482,
        "endColumn": 21,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "llama2_classifier",
        "line": 482,
        "column": 0,
        "endLine": 482,
        "endColumn": 21,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_classifier",
        "line": 561,
        "column": 0,
        "endLine": 561,
        "endColumn": 26,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (18/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_classifier",
        "line": 561,
        "column": 0,
        "endLine": 561,
        "endColumn": 26,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (26/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._component_builders",
        "obj": "lora_llama2_classifier",
        "line": 693,
        "column": 8,
        "endLine": 693,
        "endColumn": 39,
        "path": "torchtune/models/llama2/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.eos_id",
        "line": 74,
        "column": 4,
        "endLine": 74,
        "endColumn": 14,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.bos_id",
        "line": 78,
        "column": 4,
        "endLine": 78,
        "endColumn": 14,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.pad_id",
        "line": 82,
        "column": 4,
        "endLine": 82,
        "endColumn": 14,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.vocab_size",
        "line": 86,
        "column": 4,
        "endLine": 86,
        "endColumn": 18,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.encode",
        "line": 89,
        "column": 4,
        "endLine": 89,
        "endColumn": 14,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.decode",
        "line": 103,
        "column": 4,
        "endLine": 103,
        "endColumn": 14,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama2._tokenizer",
        "obj": "Llama2Tokenizer.tokenize_messages",
        "line": 109,
        "column": 4,
        "endLine": 109,
        "endColumn": 25,
        "path": "torchtune/models/llama2/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'Llama2Tokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._prompt_template",
        "obj": "Llama2ChatTemplate.__call__",
        "line": 52,
        "column": 12,
        "endLine": 72,
        "endColumn": 41,
        "path": "torchtune/models/llama2/_prompt_template.py",
        "symbol": "no-else-continue",
        "message": "Unnecessary \"elif\" after \"continue\", remove the leading \"el\" from \"elif\"",
        "message-id": "R1724"
    },
    {
        "type": "error",
        "module": "torchtune.models.llama2._prompt_template",
        "obj": "Llama2ChatTemplate.__call__",
        "line": 76,
        "column": 28,
        "endLine": 76,
        "endColumn": 35,
        "path": "torchtune/models/llama2/_prompt_template.py",
        "symbol": "possibly-used-before-assignment",
        "message": "Possibly using variable 'content' before assignment",
        "message-id": "E0606"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama2._prompt_template",
        "obj": "Llama2ChatTemplate",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 24,
        "path": "torchtune/models/llama2/_prompt_template.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma",
        "obj": "",
        "line": 30,
        "column": 4,
        "endLine": 30,
        "endColumn": 22,
        "path": "torchtune/models/gemma/__init__.py",
        "symbol": "undefined-all-variable",
        "message": "Undefined variable name 'gemma_hf_to_tune' in __all__",
        "message-id": "E0603"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma",
        "obj": "",
        "line": 31,
        "column": 4,
        "endLine": 31,
        "endColumn": 22,
        "path": "torchtune/models/gemma/__init__.py",
        "symbol": "undefined-all-variable",
        "message": "Undefined variable name 'gemma_tune_to_hf' in __all__",
        "message-id": "E0603"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "",
        "line": 146,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "",
        "line": 147,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "",
        "line": 18,
        "column": 0,
        "endLine": 21,
        "endColumn": 3,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "lora_gemma_2b",
        "line": 66,
        "column": 0,
        "endLine": 66,
        "endColumn": 17,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "lora_gemma_7b",
        "line": 148,
        "column": 0,
        "endLine": 148,
        "endColumn": 17,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._model_builders",
        "obj": "",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 29,
        "path": "torchtune/models/gemma/_model_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"functools.partial\" should be placed before first party imports \"torchtune.models.gemma._component_builders.gemma\", \"torchtune.models.gemma.transformer.GemmaTransformerDecoder\", \"torchtune.models.gemma._tokenizer.GemmaTokenizer\", \"torchtune.modules.peft.LORA_ATTN_MODULES\", \"torchtune.data._prompt_templates._TemplateType\", \"torchtune.config._utils._get_prompt_template\" ",
        "message-id": "C0411"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "",
        "line": 248,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "",
        "line": 24,
        "column": 0,
        "endLine": 34,
        "endColumn": 3,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "gemma",
        "line": 37,
        "column": 0,
        "endLine": 37,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "gemma",
        "line": 37,
        "column": 0,
        "endLine": 37,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma",
        "line": 132,
        "column": 0,
        "endLine": 132,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (19/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma",
        "line": 132,
        "column": 0,
        "endLine": 132,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (24/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma",
        "line": 245,
        "column": 8,
        "endLine": 245,
        "endColumn": 39,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 258,
        "column": 0,
        "endLine": 258,
        "endColumn": 29,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 258,
        "column": 0,
        "endLine": 258,
        "endColumn": 29,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (13/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 258,
        "column": 0,
        "endLine": 258,
        "endColumn": 29,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 285,
        "column": 8,
        "endLine": 293,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 302,
        "column": 8,
        "endLine": 310,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 319,
        "column": 8,
        "endLine": 327,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_self_attention",
        "line": 336,
        "column": 8,
        "endLine": 344,
        "endColumn": 9,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_mlp",
        "line": 370,
        "column": 0,
        "endLine": 370,
        "endColumn": 18,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_mlp",
        "line": 370,
        "column": 0,
        "endLine": 370,
        "endColumn": 18,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_mlp",
        "line": 381,
        "column": 16,
        "endLine": 389,
        "endColumn": 5,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_mlp",
        "line": 390,
        "column": 16,
        "endLine": 398,
        "endColumn": 5,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "error",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "lora_gemma_mlp",
        "line": 399,
        "column": 14,
        "endLine": 407,
        "endColumn": 5,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "unexpected-keyword-arg",
        "message": "Unexpected keyword argument 'use_dora' in constructor call",
        "message-id": "E1123"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "",
        "line": 8,
        "column": 0,
        "endLine": 8,
        "endColumn": 23,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"typing.List\" should be placed before third party import \"torch.nn\"",
        "message-id": "C0411"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._component_builders",
        "obj": "",
        "line": 9,
        "column": 0,
        "endLine": 9,
        "endColumn": 29,
        "path": "torchtune/models/gemma/_component_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"functools.partial\" should be placed before third party import \"torch.nn\"",
        "message-id": "C0411"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma.transformer",
        "obj": "",
        "line": 10,
        "column": 0,
        "endLine": 10,
        "endColumn": 21,
        "path": "torchtune/models/gemma/transformer.py",
        "symbol": "consider-using-from-import",
        "message": "Use 'from torch import nn' instead",
        "message-id": "R0402"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma.transformer",
        "obj": "GemmaTransformerDecoder",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 29,
        "path": "torchtune/models/gemma/transformer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (9/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma.transformer",
        "obj": "GemmaTransformerDecoder.__init__",
        "line": 48,
        "column": 4,
        "endLine": 48,
        "endColumn": 16,
        "path": "torchtune/models/gemma/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (9/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma.transformer",
        "obj": "GemmaTransformerDecoder.forward",
        "line": 141,
        "column": 8,
        "endLine": 141,
        "endColumn": 11,
        "path": "torchtune/models/gemma/transformer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'bsz'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma.transformer",
        "obj": "GemmaTransformerDecoder.forward",
        "line": 141,
        "column": 13,
        "endLine": 141,
        "endColumn": 20,
        "path": "torchtune/models/gemma/transformer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'seq_len'",
        "message-id": "W0612"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.eos_id",
        "line": 64,
        "column": 4,
        "endLine": 64,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.bos_id",
        "line": 68,
        "column": 4,
        "endLine": 68,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.pad_id",
        "line": 72,
        "column": 4,
        "endLine": 72,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.vocab_size",
        "line": 76,
        "column": 4,
        "endLine": 76,
        "endColumn": 18,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.encode",
        "line": 79,
        "column": 4,
        "endLine": 79,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.decode",
        "line": 93,
        "column": 4,
        "endLine": 93,
        "endColumn": 14,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.gemma._tokenizer",
        "obj": "GemmaTokenizer.tokenize_messages",
        "line": 99,
        "column": 4,
        "endLine": 99,
        "endColumn": 25,
        "path": "torchtune/models/gemma/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'GemmaTokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "convention",
        "module": "torchtune.models.gemma.rms_norm",
        "obj": "GemmaRMSNorm.forward",
        "line": 21,
        "column": 4,
        "endLine": 21,
        "endColumn": 15,
        "path": "torchtune/models/gemma/rms_norm.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.gemma.rms_norm",
        "obj": "GemmaRMSNorm",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 18,
        "path": "torchtune/models/gemma/rms_norm.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._position_embeddings",
        "obj": "Phi3RotaryPositionalEmbeddings.rope_init",
        "line": 43,
        "column": 4,
        "endLine": 43,
        "endColumn": 17,
        "path": "torchtune/models/phi3/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._position_embeddings",
        "obj": "Phi3RotaryPositionalEmbeddings.build_rope_cache",
        "line": 51,
        "column": 4,
        "endLine": 51,
        "endColumn": 24,
        "path": "torchtune/models/phi3/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._model_builders",
        "obj": "",
        "line": 14,
        "column": 0,
        "endLine": 17,
        "endColumn": 3,
        "path": "torchtune/models/phi3/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._model_builders",
        "obj": "lora_phi3_mini",
        "line": 74,
        "column": 0,
        "endLine": 74,
        "endColumn": 18,
        "path": "torchtune/models/phi3/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._model_builders",
        "obj": "",
        "line": 8,
        "column": 0,
        "endLine": 8,
        "endColumn": 29,
        "path": "torchtune/models/phi3/_model_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"functools.partial\" should be placed before first party imports \"torchtune.models.phi3._component_builders.phi3\", \"torchtune.models.phi3._tokenizer.Phi3MiniTokenizer\", \"torchtune.modules.TransformerDecoder\", \"torchtune.modules.peft.LORA_ATTN_MODULES\" ",
        "message-id": "C0411"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "",
        "line": 225,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "",
        "line": 26,
        "column": 0,
        "endLine": 36,
        "endColumn": 3,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "phi3",
        "line": 38,
        "column": 0,
        "endLine": 38,
        "endColumn": 8,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "phi3",
        "line": 38,
        "column": 0,
        "endLine": 38,
        "endColumn": 8,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3",
        "line": 121,
        "column": 0,
        "endLine": 121,
        "endColumn": 13,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (18/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3",
        "line": 121,
        "column": 0,
        "endLine": 121,
        "endColumn": 13,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (25/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3",
        "line": 246,
        "column": 8,
        "endLine": 246,
        "endColumn": 39,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3_self_attention",
        "line": 255,
        "column": 0,
        "endLine": 255,
        "endColumn": 28,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3_self_attention",
        "line": 255,
        "column": 0,
        "endLine": 255,
        "endColumn": 28,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3_mlp",
        "line": 396,
        "column": 0,
        "endLine": 396,
        "endColumn": 17,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._component_builders",
        "obj": "lora_phi3_mlp",
        "line": 396,
        "column": 0,
        "endLine": 396,
        "endColumn": 17,
        "path": "torchtune/models/phi3/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.vocab_size",
        "line": 83,
        "column": 4,
        "endLine": 83,
        "endColumn": 18,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.bos_id",
        "line": 87,
        "column": 4,
        "endLine": 87,
        "endColumn": 14,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.encode",
        "line": 90,
        "column": 4,
        "endLine": 90,
        "endColumn": 14,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.decode",
        "line": 117,
        "column": 12,
        "endLine": 120,
        "endColumn": 47,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "no-else-continue",
        "message": "Unnecessary \"else\" after \"continue\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1724"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.decode",
        "line": 117,
        "column": 15,
        "endLine": 117,
        "endColumn": 56,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "chained-comparison",
        "message": "Simplify chained comparison between the operands",
        "message-id": "R1716"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.tokenize_messages",
        "line": 123,
        "column": 4,
        "endLine": 123,
        "endColumn": 25,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'Phi3MiniTokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.tokenize_messages",
        "line": 244,
        "column": 52,
        "endLine": 244,
        "endColumn": 59,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "undefined-loop-variable",
        "message": "Using possibly undefined loop variable 'message'",
        "message-id": "W0631"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.phi3._tokenizer",
        "obj": "Phi3MiniTokenizer.tokenize_messages",
        "line": 123,
        "column": 4,
        "endLine": 123,
        "endColumn": 25,
        "path": "torchtune/models/phi3/_tokenizer.py",
        "symbol": "too-many-branches",
        "message": "Too many branches (14/12)",
        "message-id": "R0912"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "",
        "line": 12,
        "column": 1,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "fixme",
        "message": "TODO (@Felipe): add load hooks + interpolation on positional encodings,",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TokenPositionalEmbedding.forward",
        "line": 42,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TokenPositionalEmbedding",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 30,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TiledTokenPositionalEmbedding",
        "line": 54,
        "column": 0,
        "endLine": 54,
        "endColumn": 35,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TilePositionalEmbedding.forward",
        "line": 178,
        "column": 8,
        "endLine": 178,
        "endColumn": 22,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'bsz_and_n_imgs'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TilePositionalEmbedding.forward",
        "line": 178,
        "column": 24,
        "endLine": 178,
        "endColumn": 31,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'n_tiles'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TilePositionalEmbedding.forward",
        "line": 178,
        "column": 33,
        "endLine": 178,
        "endColumn": 41,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'n_tokens'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TilePositionalEmbedding.forward",
        "line": 178,
        "column": 43,
        "endLine": 178,
        "endColumn": 52,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'embed_dim'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._position_embeddings",
        "obj": "TilePositionalEmbedding",
        "line": 142,
        "column": 0,
        "endLine": 142,
        "endColumn": 29,
        "path": "torchtune/models/clip/_position_embeddings.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._transforms",
        "obj": "CLIPImageTransform",
        "line": 26,
        "column": 0,
        "endLine": 26,
        "endColumn": 24,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (8/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._transforms",
        "obj": "CLIPImageTransform.__init__",
        "line": 93,
        "column": 4,
        "endLine": 93,
        "endColumn": 16,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._transforms",
        "obj": "CLIPImageTransform.__init__",
        "line": 115,
        "column": 12,
        "endLine": 115,
        "endColumn": 32,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "self-assigning-variable",
        "message": "Assigning the same variable 'possible_resolutions' to itself",
        "message-id": "W0127"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._transforms",
        "obj": "CLIPImageTransform.__init__",
        "line": 118,
        "column": 8,
        "endLine": 120,
        "endColumn": 9,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "logging-fstring-interpolation",
        "message": "Use lazy % formatting in logging functions",
        "message-id": "W1203"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._transforms",
        "obj": "CLIPImageTransform",
        "line": 26,
        "column": 0,
        "endLine": 26,
        "endColumn": 24,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._transforms",
        "obj": "",
        "line": 21,
        "column": 0,
        "endLine": 21,
        "endColumn": 53,
        "path": "torchtune/models/clip/_transforms.py",
        "symbol": "wrong-import-order",
        "message": "third party import \"torchvision.transforms.v2.functional\" should be placed before first party imports \"torchtune.modules.transforms.vision_utils.get_canvas_best_fit.find_supported_resolutions\", \"torchtune.modules.transforms.vision_utils.resize_with_pad.resize_with_pad\", \"torchtune.modules.transforms.vision_utils.tile_crop.tile_crop\" ",
        "message-id": "C0411"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 60,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 64,
        "column": 26,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 65,
        "column": 24,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 66,
        "column": 51,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 67,
        "column": 20,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 68,
        "column": 36,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 69,
        "column": 28,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 70,
        "column": 25,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 71,
        "column": 24,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 79,
        "column": 32,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 80,
        "column": 34,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 86,
        "column": 40,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 87,
        "column": 32,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 88,
        "column": 34,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "trailing-whitespace",
        "message": "Trailing whitespace",
        "message-id": "C0303"
    },
    {
        "type": "warning",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 61,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO (Felipe): Replace with torchtune native encoder module",
        "message-id": "W0511"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._component_builders",
        "obj": "clip_vision_encoder",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 23,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (11/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.clip._component_builders",
        "obj": "clip_vision_encoder",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 23,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.clip._component_builders",
        "obj": "",
        "line": 7,
        "column": 0,
        "endLine": 7,
        "endColumn": 14,
        "path": "torchtune/models/clip/_component_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"logging\" should be placed before third party import \"torch\" and first party imports \"torchtune.modules.vision_transformer.VisionTransformer\", \"torchtune.models.clip._position_embeddings.TokenPositionalEmbedding\" ",
        "message-id": "C0411"
    },
    {
        "type": "convention",
        "module": "torchtune.models.qwen2._positional_embeddings",
        "obj": "Qwen2RotaryPositionalEmbeddings.rope_init",
        "line": 43,
        "column": 4,
        "endLine": 43,
        "endColumn": 17,
        "path": "torchtune/models/qwen2/_positional_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.qwen2._positional_embeddings",
        "obj": "Qwen2RotaryPositionalEmbeddings.build_rope_cache",
        "line": 51,
        "column": 4,
        "endLine": 51,
        "endColumn": 24,
        "path": "torchtune/models/qwen2/_positional_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._model_builders",
        "obj": "",
        "line": 16,
        "column": 0,
        "endLine": 20,
        "endColumn": 3,
        "path": "torchtune/models/qwen2/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._model_builders",
        "obj": "lora_qwen2_7b",
        "line": 131,
        "column": 0,
        "endLine": 131,
        "endColumn": 17,
        "path": "torchtune/models/qwen2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._model_builders",
        "obj": "lora_qwen2_0_5b",
        "line": 185,
        "column": 0,
        "endLine": 185,
        "endColumn": 19,
        "path": "torchtune/models/qwen2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._model_builders",
        "obj": "lora_qwen2_1_5b",
        "line": 241,
        "column": 0,
        "endLine": 241,
        "endColumn": 19,
        "path": "torchtune/models/qwen2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "",
        "line": 256,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "",
        "line": 291,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "",
        "line": 26,
        "column": 0,
        "endLine": 36,
        "endColumn": 3,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "qwen2",
        "line": 39,
        "column": 0,
        "endLine": 39,
        "endColumn": 9,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (11/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "qwen2",
        "line": 39,
        "column": 0,
        "endLine": 39,
        "endColumn": 9,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "qwen2",
        "line": 108,
        "column": 4,
        "endLine": 128,
        "endColumn": 9,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2",
        "line": 141,
        "column": 0,
        "endLine": 141,
        "endColumn": 14,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (19/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2",
        "line": 141,
        "column": 0,
        "endLine": 141,
        "endColumn": 14,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (26/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2",
        "line": 288,
        "column": 8,
        "endLine": 288,
        "endColumn": 39,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2_self_attention",
        "line": 301,
        "column": 0,
        "endLine": 301,
        "endColumn": 29,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2_self_attention",
        "line": 301,
        "column": 0,
        "endLine": 301,
        "endColumn": 29,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2_mlp",
        "line": 425,
        "column": 0,
        "endLine": 425,
        "endColumn": 18,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "lora_qwen2_mlp",
        "line": 425,
        "column": 0,
        "endLine": 425,
        "endColumn": 18,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 20,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "wrong-import-order",
        "message": "third party import \"torch.nn\" should be placed before first party import \"torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook\" ",
        "message-id": "C0411"
    },
    {
        "type": "convention",
        "module": "torchtune.models.qwen2._component_builders",
        "obj": "",
        "line": 13,
        "column": 0,
        "endLine": 13,
        "endColumn": 93,
        "path": "torchtune/models/qwen2/_component_builders.py",
        "symbol": "ungrouped-imports",
        "message": "Imports from package torchtune are not grouped",
        "message-id": "C0412"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._convert_weights",
        "obj": "qwen2_hf_to_tune",
        "line": 37,
        "column": 0,
        "endLine": 37,
        "endColumn": 20,
        "path": "torchtune/models/qwen2/_convert_weights.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._convert_weights",
        "obj": "qwen2_hf_to_tune",
        "line": 40,
        "column": 4,
        "endLine": 40,
        "endColumn": 21,
        "path": "torchtune/models/qwen2/_convert_weights.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'num_kv_heads'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._convert_weights",
        "obj": "qwen2_tune_to_hf",
        "line": 82,
        "column": 0,
        "endLine": 82,
        "endColumn": 20,
        "path": "torchtune/models/qwen2/_convert_weights.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._convert_weights",
        "obj": "qwen2_tune_to_hf",
        "line": 85,
        "column": 4,
        "endLine": 85,
        "endColumn": 21,
        "path": "torchtune/models/qwen2/_convert_weights.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'num_kv_heads'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._convert_weights",
        "obj": "qwen2_tune_to_hf",
        "line": 88,
        "column": 4,
        "endLine": 88,
        "endColumn": 29,
        "path": "torchtune/models/qwen2/_convert_weights.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'tie_word_embeddings'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer",
        "line": 76,
        "column": 0,
        "endLine": 76,
        "endColumn": 20,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (20/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer.__init__",
        "line": 119,
        "column": 4,
        "endLine": 119,
        "endColumn": 16,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer.__init__",
        "line": 119,
        "column": 4,
        "endLine": 119,
        "endColumn": 16,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer._bpe_without_cache",
        "line": 208,
        "column": 12,
        "endLine": 211,
        "endColumn": 39,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "no-else-break",
        "message": "Unnecessary \"else\" after \"break\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1723"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer.tokenize_messages",
        "line": 327,
        "column": 4,
        "endLine": 327,
        "endColumn": 25,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'Qwen2Tokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.models.qwen2._tokenizer",
        "obj": "Qwen2Tokenizer.tokenize_messages",
        "line": 356,
        "column": 12,
        "endLine": 356,
        "endColumn": 17,
        "path": "torchtune/models/qwen2/_tokenizer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'index'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.code_llama2._model_builders",
        "obj": "lora_code_llama2_7b",
        "line": 38,
        "column": 0,
        "endLine": 38,
        "endColumn": 23,
        "path": "torchtune/models/code_llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.code_llama2._model_builders",
        "obj": "lora_code_llama2_13b",
        "line": 122,
        "column": 0,
        "endLine": 122,
        "endColumn": 24,
        "path": "torchtune/models/code_llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.code_llama2._model_builders",
        "obj": "lora_code_llama2_70b",
        "line": 209,
        "column": 0,
        "endLine": 209,
        "endColumn": 24,
        "path": "torchtune/models/code_llama2/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "",
        "line": 62,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "fixme",
        "message": "TODO: delete this once all our recipes are moved off of FSDP1 since we",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "",
        "line": 149,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "fixme",
        "message": "TODO: remove once our distributed recipes are on FSDP2",
        "message-id": "W0511"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 22,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (8/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.__init__",
        "line": 40,
        "column": 4,
        "endLine": 40,
        "endColumn": 16,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.reset_parameters",
        "line": 64,
        "column": 4,
        "endLine": 64,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "error",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.reset_parameters",
        "line": 65,
        "column": 8,
        "endLine": 65,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'scale_factor' in method call",
        "message-id": "E1120"
    },
    {
        "type": "error",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.reset_parameters",
        "line": 65,
        "column": 8,
        "endLine": 65,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'low_freq_factor' in method call",
        "message-id": "E1120"
    },
    {
        "type": "error",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.reset_parameters",
        "line": 65,
        "column": 8,
        "endLine": 65,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'high_freq_factor' in method call",
        "message-id": "E1120"
    },
    {
        "type": "error",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.reset_parameters",
        "line": 65,
        "column": 8,
        "endLine": 65,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "no-value-for-parameter",
        "message": "No value for argument 'old_context_len' in method call",
        "message-id": "E1120"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.rope_init",
        "line": 67,
        "column": 4,
        "endLine": 67,
        "endColumn": 17,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.build_rope_cache",
        "line": 85,
        "column": 4,
        "endLine": 85,
        "endColumn": 24,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.apply_scaling",
        "line": 100,
        "column": 4,
        "endLine": 100,
        "endColumn": 21,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._position_embeddings",
        "obj": "Llama3ScaledRoPE.apply_scaling",
        "line": 100,
        "column": 4,
        "endLine": 100,
        "endColumn": 21,
        "path": "torchtune/models/llama3_1/_position_embeddings.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "",
        "line": 17,
        "column": 0,
        "endLine": 21,
        "endColumn": 3,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "lora_llama3_1_8b",
        "line": 84,
        "column": 0,
        "endLine": 84,
        "endColumn": 20,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "lora_llama3_1_70b",
        "line": 137,
        "column": 0,
        "endLine": 137,
        "endColumn": 21,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "",
        "line": 6,
        "column": 0,
        "endLine": 6,
        "endColumn": 33,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "unused-import",
        "message": "Unused Optional imported from typing",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "",
        "line": 12,
        "column": 0,
        "endLine": 12,
        "endColumn": 62,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "unused-import",
        "message": "Unused Llama3Tokenizer imported from torchtune.models.llama3._tokenizer",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._model_builders",
        "obj": "",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 64,
        "path": "torchtune/models/llama3_1/_model_builders.py",
        "symbol": "unused-import",
        "message": "Unused parse_hf_tokenizer_json imported from torchtune.modules.tokenizers",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "",
        "line": 239,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "",
        "line": 29,
        "column": 0,
        "endLine": 39,
        "endColumn": 3,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "llama3_1",
        "line": 44,
        "column": 0,
        "endLine": 44,
        "endColumn": 12,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (11/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "llama3_1",
        "line": 44,
        "column": 0,
        "endLine": 44,
        "endColumn": 12,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (19/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_1",
        "line": 137,
        "column": 0,
        "endLine": 137,
        "endColumn": 17,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (18/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_1",
        "line": 137,
        "column": 0,
        "endLine": 137,
        "endColumn": 17,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (26/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_1",
        "line": 260,
        "column": 8,
        "endLine": 260,
        "endColumn": 39,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_1_self_attention",
        "line": 267,
        "column": 0,
        "endLine": 267,
        "endColumn": 32,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_1_self_attention",
        "line": 267,
        "column": 0,
        "endLine": 267,
        "endColumn": 32,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_mlp",
        "line": 404,
        "column": 0,
        "endLine": 404,
        "endColumn": 19,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "lora_llama3_mlp",
        "line": 404,
        "column": 0,
        "endLine": 404,
        "endColumn": 19,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "",
        "line": 8,
        "column": 0,
        "endLine": 8,
        "endColumn": 42,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "unused-import",
        "message": "Unused Literal imported from typing",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.llama3_1._component_builders",
        "obj": "",
        "line": 15,
        "column": 0,
        "endLine": 23,
        "endColumn": 1,
        "path": "torchtune/models/llama3_1/_component_builders.py",
        "symbol": "unused-import",
        "message": "Unused KVCache imported from torchtune.modules",
        "message-id": "W0611"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._model_builders",
        "obj": "",
        "line": 23,
        "column": 0,
        "endLine": 26,
        "endColumn": 3,
        "path": "torchtune/models/mistral/_model_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._model_builders",
        "obj": "lora_mistral_7b",
        "line": 70,
        "column": 0,
        "endLine": 70,
        "endColumn": 19,
        "path": "torchtune/models/mistral/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._model_builders",
        "obj": "lora_mistral_reward_7b",
        "line": 154,
        "column": 0,
        "endLine": 154,
        "endColumn": 26,
        "path": "torchtune/models/mistral/_model_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._model_builders",
        "obj": "",
        "line": 20,
        "column": 0,
        "endLine": 20,
        "endColumn": 29,
        "path": "torchtune/models/mistral/_model_builders.py",
        "symbol": "wrong-import-order",
        "message": "standard import \"functools.partial\" should be placed before first party imports \"torchtune.models.mistral._component_builders.mistral\", \"torchtune.data._prompt_templates._TemplateType\", \"torchtune.config._utils._get_prompt_template\", \"torchtune.modules.TransformerDecoder\", \"torchtune.models.mistral._tokenizer.MistralTokenizer\", \"torchtune.modules.peft.LORA_ATTN_MODULES\" ",
        "message-id": "C0411"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "",
        "line": 245,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "",
        "line": 269,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "",
        "line": 648,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO: quantize_base is not applied to final output_proj currently.",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "",
        "line": 678,
        "column": 17,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "fixme",
        "message": "TODO this is clowny, figure out a better way to get what precision the rest",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "",
        "line": 25,
        "column": 0,
        "endLine": 35,
        "endColumn": 3,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "pointless-string-statement",
        "message": "String statement has no effect",
        "message-id": "W0105"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "mistral",
        "line": 38,
        "column": 0,
        "endLine": 38,
        "endColumn": 11,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "mistral",
        "line": 38,
        "column": 0,
        "endLine": 38,
        "endColumn": 11,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral",
        "line": 142,
        "column": 0,
        "endLine": 142,
        "endColumn": 16,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (18/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral",
        "line": 142,
        "column": 0,
        "endLine": 142,
        "endColumn": 16,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (25/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral",
        "line": 266,
        "column": 8,
        "endLine": 266,
        "endColumn": 39,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_self_attention",
        "line": 279,
        "column": 0,
        "endLine": 279,
        "endColumn": 31,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_self_attention",
        "line": 279,
        "column": 0,
        "endLine": 279,
        "endColumn": 31,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (20/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_mlp",
        "line": 421,
        "column": 0,
        "endLine": 421,
        "endColumn": 20,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_mlp",
        "line": 421,
        "column": 0,
        "endLine": 421,
        "endColumn": 20,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "mistral_classifier",
        "line": 463,
        "column": 0,
        "endLine": 463,
        "endColumn": 22,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (11/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "mistral_classifier",
        "line": 463,
        "column": 0,
        "endLine": 463,
        "endColumn": 22,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_classifier",
        "line": 544,
        "column": 0,
        "endLine": 544,
        "endColumn": 27,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (19/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_classifier",
        "line": 544,
        "column": 0,
        "endLine": 544,
        "endColumn": 27,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (26/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._component_builders",
        "obj": "lora_mistral_classifier",
        "line": 675,
        "column": 8,
        "endLine": 675,
        "endColumn": 39,
        "path": "torchtune/models/mistral/_component_builders.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _register_state_dict_hook of a client class",
        "message-id": "W0212"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._tokenizer",
        "obj": "MistralTokenizer.eos_id",
        "line": 66,
        "column": 4,
        "endLine": 66,
        "endColumn": 14,
        "path": "torchtune/models/mistral/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._tokenizer",
        "obj": "MistralTokenizer.bos_id",
        "line": 70,
        "column": 4,
        "endLine": 70,
        "endColumn": 14,
        "path": "torchtune/models/mistral/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._tokenizer",
        "obj": "MistralTokenizer.pad_id",
        "line": 74,
        "column": 4,
        "endLine": 74,
        "endColumn": 14,
        "path": "torchtune/models/mistral/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.models.mistral._tokenizer",
        "obj": "MistralTokenizer.vocab_size",
        "line": 78,
        "column": 4,
        "endLine": 78,
        "endColumn": 18,
        "path": "torchtune/models/mistral/_tokenizer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.models.mistral._tokenizer",
        "obj": "MistralTokenizer.tokenize_messages",
        "line": 124,
        "column": 4,
        "endLine": 124,
        "endColumn": 25,
        "path": "torchtune/models/mistral/_tokenizer.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'MistralTokenizer.tokenize_messages' method",
        "message-id": "W0221"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._prompt_template",
        "obj": "MistralChatTemplate.__call__",
        "line": 57,
        "column": 12,
        "endLine": 66,
        "endColumn": 17,
        "path": "torchtune/models/mistral/_prompt_template.py",
        "symbol": "no-else-raise",
        "message": "Unnecessary \"else\" after \"raise\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1720"
    },
    {
        "type": "refactor",
        "module": "torchtune.models.mistral._prompt_template",
        "obj": "MistralChatTemplate",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 25,
        "path": "torchtune/models/mistral/_prompt_template.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune._cli.run",
        "obj": "",
        "line": 82,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/_cli/run.py",
        "symbol": "fixme",
        "message": "TODO (rohan-varma): Add check that nproc_per_node <= cuda device count. Currently,",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune._cli.run",
        "obj": "Run._add_arguments",
        "line": 68,
        "column": 22,
        "endLine": 68,
        "endColumn": 49,
        "path": "torchtune/_cli/run.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _actions of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune._cli.run",
        "obj": "Run._add_arguments",
        "line": 78,
        "column": 12,
        "endLine": 78,
        "endColumn": 36,
        "path": "torchtune/_cli/run.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _add_action of a client class",
        "message-id": "W0212"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.run",
        "obj": "Run._get_recipe",
        "line": 101,
        "column": 4,
        "endLine": 101,
        "endColumn": 19,
        "path": "torchtune/_cli/run.py",
        "symbol": "inconsistent-return-statements",
        "message": "Either all return statements in a function should return an expression, or none of them should.",
        "message-id": "R1710"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.run",
        "obj": "Run._get_config",
        "line": 114,
        "column": 4,
        "endLine": 114,
        "endColumn": 19,
        "path": "torchtune/_cli/run.py",
        "symbol": "inconsistent-return-statements",
        "message": "Either all return statements in a function should return an expression, or none of them should.",
        "message-id": "R1710"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.run",
        "obj": "Run",
        "line": 24,
        "column": 0,
        "endLine": 24,
        "endColumn": 9,
        "path": "torchtune/_cli/run.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune._cli.run",
        "obj": "",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 82,
        "path": "torchtune/_cli/run.py",
        "symbol": "wrong-import-order",
        "message": "third party import \"torch.distributed.run.get_args_parser\" should be placed before first party import \"torchtune\" ",
        "message-id": "C0411"
    },
    {
        "type": "warning",
        "module": "torchtune._cli.download",
        "obj": "Download._download_cmd",
        "line": 144,
        "column": 15,
        "endLine": 144,
        "endColumn": 24,
        "path": "torchtune/_cli/download.py",
        "symbol": "broad-exception-caught",
        "message": "Catching too general exception Exception",
        "message-id": "W0718"
    },
    {
        "type": "convention",
        "module": "torchtune._cli.download",
        "obj": "Download._download_cmd",
        "line": 145,
        "column": 12,
        "endLine": 145,
        "endColumn": 28,
        "path": "torchtune/_cli/download.py",
        "symbol": "import-outside-toplevel",
        "message": "Import outside toplevel (traceback)",
        "message-id": "C0415"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.download",
        "obj": "Download",
        "line": 19,
        "column": 0,
        "endLine": 19,
        "endColumn": 14,
        "path": "torchtune/_cli/download.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune._cli.ls",
        "obj": "List._ls_cmd",
        "line": 45,
        "column": 22,
        "endLine": 45,
        "endColumn": 46,
        "path": "torchtune/_cli/ls.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.ls",
        "obj": "List",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 10,
        "path": "torchtune/_cli/ls.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.cp",
        "obj": "Copy",
        "line": 18,
        "column": 0,
        "endLine": 18,
        "endColumn": 10,
        "path": "torchtune/_cli/cp.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.validate",
        "obj": "Validate",
        "line": 18,
        "column": 0,
        "endLine": 18,
        "endColumn": 14,
        "path": "torchtune/_cli/validate.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune._cli.tune",
        "obj": "main",
        "line": 46,
        "column": 0,
        "endLine": 46,
        "endColumn": 8,
        "path": "torchtune/_cli/tune.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune._cli.subcommand",
        "obj": "Subcommand.create",
        "line": 13,
        "column": 4,
        "endLine": 13,
        "endColumn": 14,
        "path": "torchtune/_cli/subcommand.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune._cli.subcommand",
        "obj": "Subcommand",
        "line": 8,
        "column": 0,
        "endLine": 8,
        "endColumn": 16,
        "path": "torchtune/_cli/subcommand.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.attention",
        "obj": "MultiHeadAttention",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 24,
        "path": "torchtune/modules/attention.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (15/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.attention",
        "obj": "MultiHeadAttention.__init__",
        "line": 82,
        "column": 4,
        "endLine": 82,
        "endColumn": 16,
        "path": "torchtune/modules/attention.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (16/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.attention",
        "obj": "MultiHeadAttention.__init__",
        "line": 82,
        "column": 4,
        "endLine": 82,
        "endColumn": 16,
        "path": "torchtune/modules/attention.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (16/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.position_embeddings",
        "obj": "",
        "line": 46,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/position_embeddings.py",
        "symbol": "fixme",
        "message": "TODO: delete this once all our recipes are moved off of FSDP1 since we",
        "message-id": "W0511"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.position_embeddings",
        "obj": "RotaryPositionalEmbeddings.reset_parameters",
        "line": 48,
        "column": 4,
        "endLine": 48,
        "endColumn": 24,
        "path": "torchtune/modules/position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.position_embeddings",
        "obj": "RotaryPositionalEmbeddings.rope_init",
        "line": 51,
        "column": 4,
        "endLine": 51,
        "endColumn": 17,
        "path": "torchtune/modules/position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.position_embeddings",
        "obj": "RotaryPositionalEmbeddings.build_rope_cache",
        "line": 59,
        "column": 4,
        "endLine": 59,
        "endColumn": 24,
        "path": "torchtune/modules/position_embeddings.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.vision_transformer",
        "obj": "VisionTransformer",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 23,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (11/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.vision_transformer",
        "obj": "VisionTransformer.__init__",
        "line": 196,
        "column": 4,
        "endLine": 196,
        "endColumn": 16,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (12/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.vision_transformer",
        "obj": "VisionTransformer.get_image_tokens_per_tile",
        "line": 250,
        "column": 4,
        "endLine": 250,
        "endColumn": 33,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.vision_transformer",
        "obj": "VisionTransformer.forward",
        "line": 253,
        "column": 4,
        "endLine": 253,
        "endColumn": 15,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (16/15)",
        "message-id": "R0914"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.vision_transformer",
        "obj": "CLSEmbedding.forward",
        "line": 425,
        "column": 4,
        "endLine": 425,
        "endColumn": 15,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.vision_transformer",
        "obj": "CLSEmbedding.forward",
        "line": 428,
        "column": 33,
        "endLine": 428,
        "endColumn": 41,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'n_tokens'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.vision_transformer",
        "obj": "CLSEmbedding",
        "line": 408,
        "column": 0,
        "endLine": 408,
        "endColumn": 18,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.vision_transformer",
        "obj": "CLSProjection.forward",
        "line": 449,
        "column": 4,
        "endLine": 449,
        "endColumn": 15,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.vision_transformer",
        "obj": "CLSProjection",
        "line": 433,
        "column": 0,
        "endLine": 433,
        "endColumn": 19,
        "path": "torchtune/modules/vision_transformer.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.feed_forward",
        "obj": "FeedForward.forward",
        "line": 37,
        "column": 4,
        "endLine": 37,
        "endColumn": 15,
        "path": "torchtune/modules/feed_forward.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.feed_forward",
        "obj": "FeedForward",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 17,
        "path": "torchtune/modules/feed_forward.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.kv_cache",
        "obj": "KVCache.__init__",
        "line": 27,
        "column": 4,
        "endLine": 27,
        "endColumn": 16,
        "path": "torchtune/modules/kv_cache.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "",
        "line": 242,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "fixme",
        "message": "TODO: Add support for sample packing and bring back input_pos",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "",
        "line": 271,
        "column": 5,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "fixme",
        "message": "FIXME: copy.deepcopy() is not defined on nn.module",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "",
        "line": 481,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "fixme",
        "message": "TODO: always output a list to have a consistent output type",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "",
        "line": 690,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "fixme",
        "message": "TODO: always output a list to have a consistent output type",
        "message-id": "W0511"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerSelfAttentionLayer.__init__",
        "line": 28,
        "column": 4,
        "endLine": 28,
        "endColumn": 16,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerSelfAttentionLayer.forward",
        "line": 65,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerCrossAttentionLayer.__init__",
        "line": 128,
        "column": 4,
        "endLine": 128,
        "endColumn": 16,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerCrossAttentionLayer.forward",
        "line": 205,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/transformer.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerDecoder",
        "line": 275,
        "column": 0,
        "endLine": 275,
        "endColumn": 24,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (10/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerDecoder.__init__",
        "line": 308,
        "column": 4,
        "endLine": 308,
        "endColumn": 16,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (10/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerDecoder.forward",
        "line": 378,
        "column": 4,
        "endLine": 378,
        "endColumn": 15,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "TransformerDecoder.forward",
        "line": 429,
        "column": 8,
        "endLine": 429,
        "endColumn": 11,
        "path": "torchtune/modules/transformer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'bsz'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TiedEmbeddingTransformerDecoder",
        "line": 486,
        "column": 0,
        "endLine": 486,
        "endColumn": 37,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (9/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TiedEmbeddingTransformerDecoder.__init__",
        "line": 519,
        "column": 4,
        "endLine": 519,
        "endColumn": 16,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (9/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transformer",
        "obj": "TiedEmbeddingTransformerDecoder.forward",
        "line": 587,
        "column": 4,
        "endLine": 587,
        "endColumn": 15,
        "path": "torchtune/modules/transformer.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transformer",
        "obj": "TiedEmbeddingTransformerDecoder.forward",
        "line": 637,
        "column": 8,
        "endLine": 637,
        "endColumn": 11,
        "path": "torchtune/modules/transformer.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'bsz'",
        "message-id": "W0612"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tanh_gate",
        "obj": "TanhGate",
        "line": 12,
        "column": 0,
        "endLine": 12,
        "endColumn": 14,
        "path": "torchtune/modules/tanh_gate.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.common_utils",
        "obj": "",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 21,
        "path": "torchtune/modules/common_utils.py",
        "symbol": "consider-using-from-import",
        "message": "Use 'from torch import nn' instead",
        "message-id": "R0402"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.common_utils",
        "obj": "reparametrize_as_dtype_state_dict_post_hook",
        "line": 16,
        "column": 4,
        "endLine": 16,
        "endColumn": 20,
        "path": "torchtune/modules/common_utils.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'model'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.common_utils",
        "obj": "reparametrize_as_dtype_state_dict_post_hook",
        "line": 16,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/common_utils.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.common_utils",
        "obj": "reparametrize_as_dtype_state_dict_post_hook",
        "line": 16,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/common_utils.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rms_norm",
        "obj": "RMSNorm",
        "line": 12,
        "column": 0,
        "endLine": 12,
        "endColumn": 13,
        "path": "torchtune/modules/rms_norm.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.layer_norm",
        "obj": "Fp32LayerNorm.__init__",
        "line": 19,
        "column": 4,
        "endLine": 19,
        "endColumn": 16,
        "path": "torchtune/modules/layer_norm.py",
        "symbol": "useless-parent-delegation",
        "message": "Useless parent or super() delegation in method '__init__'",
        "message-id": "W0246"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.layer_norm",
        "obj": "Fp32LayerNorm",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 19,
        "path": "torchtune/modules/layer_norm.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 32,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (8/7)",
        "message-id": "R0902"
    },
    {
        "type": "error",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.__init__",
        "line": 35,
        "column": 8,
        "endLine": 35,
        "endColumn": 22,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-member",
        "message": "Instance of 'SentencePieceProcessor' has no 'load' member; maybe 'Load'?",
        "message-id": "E1101"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.__init__",
        "line": 45,
        "column": 34,
        "endLine": 47,
        "endColumn": 9,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "use-a-generator",
        "message": "Use a generator instead 'any(self.spm_model.encode(c) for c in WHITESPACE_CHARS)'",
        "message-id": "R1729"
    },
    {
        "type": "error",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.__init__",
        "line": 46,
        "column": 13,
        "endLine": 46,
        "endColumn": 34,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-member",
        "message": "Instance of 'SentencePieceProcessor' has no 'encode' member; maybe 'Encode'?",
        "message-id": "E1101"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 49,
        "column": 4,
        "endLine": 49,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'SentencePieceBaseTokenizer.encode' method",
        "message-id": "W0221"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 49,
        "column": 4,
        "endLine": 49,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 80,
        "column": 8,
        "endLine": 100,
        "endColumn": 13,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "error",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 88,
        "column": 19,
        "endLine": 88,
        "endColumn": 40,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-member",
        "message": "Instance of 'SentencePieceProcessor' has no 'encode' member; maybe 'Encode'?",
        "message-id": "E1101"
    },
    {
        "type": "error",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 95,
        "column": 19,
        "endLine": 95,
        "endColumn": 40,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-member",
        "message": "Instance of 'SentencePieceProcessor' has no 'encode' member; maybe 'Encode'?",
        "message-id": "E1101"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.decode",
        "line": 102,
        "column": 4,
        "endLine": 102,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "arguments-renamed",
        "message": "Parameter 'token_ids' has been renamed to 'ids' in overriding 'SentencePieceBaseTokenizer.decode' method",
        "message-id": "W0237"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.decode",
        "line": 102,
        "column": 4,
        "endLine": 102,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'SentencePieceBaseTokenizer.decode' method",
        "message-id": "W0221"
    },
    {
        "type": "error",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.decode",
        "line": 111,
        "column": 15,
        "endLine": 111,
        "endColumn": 36,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "no-member",
        "message": "Instance of 'SentencePieceProcessor' has no 'decode' member; maybe 'Decode'?",
        "message-id": "E1101"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 83,
        "column": 16,
        "endLine": 83,
        "endColumn": 27,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "attribute-defined-outside-init",
        "message": "Attribute 'prefix' defined outside __init__",
        "message-id": "W0201"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._sentencepiece",
        "obj": "SentencePieceBaseTokenizer.encode",
        "line": 84,
        "column": 16,
        "endLine": 84,
        "endColumn": 35,
        "path": "torchtune/modules/tokenizers/_sentencepiece.py",
        "symbol": "attribute-defined-outside-init",
        "message": "Attribute 'encoded_prefix' defined outside __init__",
        "message-id": "W0201"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._tiktoken",
        "obj": "TikTokenBaseTokenizer.__init__",
        "line": 40,
        "column": 4,
        "endLine": 40,
        "endColumn": 16,
        "path": "torchtune/modules/tokenizers/_tiktoken.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.tokenizers._tiktoken",
        "obj": "TikTokenBaseTokenizer._split_long_repetitions",
        "line": 74,
        "column": 8,
        "endLine": 85,
        "endColumn": 41,
        "path": "torchtune/modules/tokenizers/_tiktoken.py",
        "symbol": "consider-using-enumerate",
        "message": "Consider using enumerate instead of iterating with range and len",
        "message-id": "C0200"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._tiktoken",
        "obj": "TikTokenBaseTokenizer.encode",
        "line": 88,
        "column": 4,
        "endLine": 88,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_tiktoken.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'TikTokenBaseTokenizer.encode' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._tiktoken",
        "obj": "TikTokenBaseTokenizer.decode",
        "line": 137,
        "column": 4,
        "endLine": 137,
        "endColumn": 14,
        "path": "torchtune/modules/tokenizers/_tiktoken.py",
        "symbol": "arguments-differ",
        "message": "Variadics removed in overriding 'TikTokenBaseTokenizer.decode' method",
        "message-id": "W0221"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._tiktoken",
        "obj": "TikTokenBaseTokenizer.decode",
        "line": 167,
        "column": 35,
        "endLine": 167,
        "endColumn": 64,
        "path": "torchtune/modules/tokenizers/_tiktoken.py",
        "symbol": "protected-access",
        "message": "Access to a protected member _special_tokens of a client class",
        "message-id": "W0212"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "BaseTokenizer.encode",
        "line": 30,
        "column": 8,
        "endLine": 30,
        "endColumn": 12,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "BaseTokenizer.decode",
        "line": 43,
        "column": 8,
        "endLine": 43,
        "endColumn": 12,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "ModelTokenizer.tokenize_messages",
        "line": 69,
        "column": 8,
        "endLine": 69,
        "endColumn": 12,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "ModelTokenizer",
        "line": 46,
        "column": 0,
        "endLine": 46,
        "endColumn": 20,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "tokenize_messages_no_special_tokens",
        "line": 153,
        "column": 31,
        "endLine": 153,
        "endColumn": 35,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "undefined-loop-variable",
        "message": "Using possibly undefined loop variable 'item'",
        "message-id": "W0631"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "tokenize_messages_no_special_tokens",
        "line": 173,
        "column": 43,
        "endLine": 173,
        "endColumn": 50,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "undefined-loop-variable",
        "message": "Using possibly undefined loop variable 'message'",
        "message-id": "W0631"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.tokenizers._utils",
        "obj": "parse_hf_tokenizer_json",
        "line": 189,
        "column": 9,
        "endLine": 189,
        "endColumn": 39,
        "path": "torchtune/modules/tokenizers/_utils.py",
        "symbol": "unspecified-encoding",
        "message": "Using open without explicitly specifying an encoding",
        "message-id": "W1514"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "",
        "line": 62,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "fixme",
        "message": "TODO: Switch to register_load_state_dict_pre_hook and",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "",
        "line": 176,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "fixme",
        "message": "TODO: Support merging the embeddings after finetuning",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "",
        "line": 183,
        "column": 9,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "fixme",
        "message": "TODO: Switch to register_load_state_dict_pre_hook and",
        "message-id": "W0511"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionLayer._state_dict_hook",
        "line": 65,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionLayer._state_dict_hook",
        "line": 65,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionLayer._load_state_dict_hook",
        "line": 79,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionLayer._load_state_dict_hook",
        "line": 79,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionEmbedding._state_dict_hook",
        "line": 186,
        "column": 44,
        "endLine": 186,
        "endColumn": 50,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'prefix'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionEmbedding._state_dict_hook",
        "line": 186,
        "column": 52,
        "endLine": 186,
        "endColumn": 61,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'keep_vars'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionEmbedding._load_state_dict_hook",
        "line": 198,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'args'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionEmbedding._load_state_dict_hook",
        "line": 198,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "FusionEmbedding.forward",
        "line": 222,
        "column": 22,
        "endLine": 222,
        "endColumn": 41,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "redefined-builtin",
        "message": "Redefining built-in 'input'",
        "message-id": "W0622"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.model_fusion._fusion",
        "obj": "DeepFusionModel.forward",
        "line": 324,
        "column": 4,
        "endLine": 324,
        "endColumn": 15,
        "path": "torchtune/modules/model_fusion/_fusion.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.low_precision._register_nf4_dispatch_ops",
        "obj": "clone",
        "line": 12,
        "column": 10,
        "endLine": 12,
        "endColumn": 14,
        "path": "torchtune/modules/low_precision/_register_nf4_dispatch_ops.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'func'",
        "message-id": "W0613"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.low_precision._register_nf4_dispatch_ops",
        "obj": "clone",
        "line": 12,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/modules/low_precision/_register_nf4_dispatch_ops.py",
        "symbol": "unused-argument",
        "message": "Unused argument 'kwargs'",
        "message-id": "W0613"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.low_precision.nf4_linear",
        "obj": "",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 21,
        "path": "torchtune/modules/low_precision/nf4_linear.py",
        "symbol": "consider-using-from-import",
        "message": "Use 'from torch import nn' instead",
        "message-id": "R0402"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.low_precision.nf4_linear",
        "obj": "FrozenNF4Linear.forward",
        "line": 49,
        "column": 22,
        "endLine": 49,
        "endColumn": 41,
        "path": "torchtune/modules/low_precision/nf4_linear.py",
        "symbol": "redefined-builtin",
        "message": "Redefining built-in 'input'",
        "message-id": "W0622"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.low_precision.nf4_linear",
        "obj": "FrozenNF4Linear",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 21,
        "path": "torchtune/modules/low_precision/nf4_linear.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft.dora",
        "obj": "DoRALinear",
        "line": 20,
        "column": 0,
        "endLine": 20,
        "endColumn": 16,
        "path": "torchtune/modules/peft/dora.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (9/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft.dora",
        "obj": "DoRALinear.__init__",
        "line": 46,
        "column": 4,
        "endLine": 46,
        "endColumn": 16,
        "path": "torchtune/modules/peft/dora.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.peft.dora",
        "obj": "DoRALinear.initialize_parameters",
        "line": 77,
        "column": 4,
        "endLine": 77,
        "endColumn": 29,
        "path": "torchtune/modules/peft/dora.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.peft.dora",
        "obj": "",
        "line": 16,
        "column": 0,
        "endLine": 16,
        "endColumn": 70,
        "path": "torchtune/modules/peft/dora.py",
        "symbol": "unused-import",
        "message": "Unused _register_nf4_dispatch_ops imported from torchtune.modules.low_precision",
        "message-id": "W0611"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft.lora",
        "obj": "LoRALinear",
        "line": 19,
        "column": 0,
        "endLine": 19,
        "endColumn": 16,
        "path": "torchtune/modules/peft/lora.py",
        "symbol": "too-many-instance-attributes",
        "message": "Too many instance attributes (11/7)",
        "message-id": "R0902"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft.lora",
        "obj": "LoRALinear.__init__",
        "line": 42,
        "column": 4,
        "endLine": 42,
        "endColumn": 16,
        "path": "torchtune/modules/peft/lora.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (8/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.peft.lora",
        "obj": "LoRALinear.initialize_parameters",
        "line": 82,
        "column": 4,
        "endLine": 82,
        "endColumn": 29,
        "path": "torchtune/modules/peft/lora.py",
        "symbol": "missing-function-docstring",
        "message": "Missing function or method docstring",
        "message-id": "C0116"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.peft.lora",
        "obj": "",
        "line": 15,
        "column": 0,
        "endLine": 15,
        "endColumn": 70,
        "path": "torchtune/modules/peft/lora.py",
        "symbol": "unused-import",
        "message": "Unused _register_nf4_dispatch_ops imported from torchtune.modules.low_precision",
        "message-id": "W0611"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.peft._utils",
        "obj": "",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 17,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "invalid-name",
        "message": "Class name \"LORA_ATTN_MODULES\" doesn't conform to PascalCase naming style",
        "message-id": "C0103"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.peft._utils",
        "obj": "AdapterModule.adapter_params",
        "line": 33,
        "column": 8,
        "endLine": 33,
        "endColumn": 12,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "AdapterModule",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 19,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_state_dict_for_lora",
        "line": 110,
        "column": 0,
        "endLine": 110,
        "endColumn": 32,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_state_dict_for_lora.<lambda>",
        "line": 155,
        "column": 20,
        "endLine": 160,
        "endColumn": 5,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "unnecessary-lambda-assignment",
        "message": "Lambda expression assigned to a variable. Define a function using the \"def\" keyword instead.",
        "message-id": "C3001"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_state_dict_for_lora.<lambda>",
        "line": 155,
        "column": 30,
        "endLine": 160,
        "endColumn": 5,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "use-a-generator",
        "message": "Use a generator instead 'any('.'.join([k, 'lora']) in x or '.'.join([k, 'magnitude']) in x for k in lora_modules)'",
        "message-id": "R1729"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "_get_lora_modules",
        "line": 210,
        "column": 11,
        "endLine": 217,
        "endColumn": 5,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "consider-using-set-comprehension",
        "message": "Consider using a set comprehension",
        "message-id": "R1718"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_missing_and_unexpected_for_lora",
        "line": 306,
        "column": 0,
        "endLine": 306,
        "endColumn": 44,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "convention",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_missing_and_unexpected_for_lora.<lambda>",
        "line": 353,
        "column": 20,
        "endLine": 358,
        "endColumn": 5,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "unnecessary-lambda-assignment",
        "message": "Lambda expression assigned to a variable. Define a function using the \"def\" keyword instead.",
        "message-id": "C3001"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.peft._utils",
        "obj": "validate_missing_and_unexpected_for_lora.<lambda>",
        "line": 353,
        "column": 30,
        "endLine": 358,
        "endColumn": 5,
        "path": "torchtune/modules/peft/_utils.py",
        "symbol": "use-a-generator",
        "message": "Use a generator instead 'any('.'.join([k, 'lora']) in x or '.'.join([k, 'magnitude']) in x for k in lora_modules)'",
        "message-id": "R1729"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf._generation",
        "obj": "generate_next_token_with_logits",
        "line": 42,
        "column": 0,
        "endLine": 42,
        "endColumn": 35,
        "path": "torchtune/modules/rlhf/_generation.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf._generation",
        "obj": "generate_with_logits",
        "line": 106,
        "column": 0,
        "endLine": 106,
        "endColumn": 24,
        "path": "torchtune/modules/rlhf/_generation.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (7/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.sequence_processing",
        "obj": "get_batch_log_probs",
        "line": 141,
        "column": 4,
        "endLine": 144,
        "endColumn": 56,
        "path": "torchtune/modules/rlhf/sequence_processing.py",
        "symbol": "no-else-return",
        "message": "Unnecessary \"else\" after \"return\", remove the \"else\" and de-indent the code inside it",
        "message-id": "R1705"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.ppo",
        "obj": "",
        "line": 10,
        "column": 0,
        "endLine": 10,
        "endColumn": 21,
        "path": "torchtune/modules/rlhf/loss/ppo.py",
        "symbol": "consider-using-from-import",
        "message": "Use 'from torch import nn' instead",
        "message-id": "R0402"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.ppo",
        "obj": "PPOLoss.forward",
        "line": 43,
        "column": 4,
        "endLine": 43,
        "endColumn": 15,
        "path": "torchtune/modules/rlhf/loss/ppo.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (9/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.ppo",
        "obj": "PPOLoss.forward",
        "line": 43,
        "column": 4,
        "endLine": 43,
        "endColumn": 15,
        "path": "torchtune/modules/rlhf/loss/ppo.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (18/15)",
        "message-id": "R0914"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.ppo",
        "obj": "PPOLoss",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 13,
        "path": "torchtune/modules/rlhf/loss/ppo.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.dpo",
        "obj": "",
        "line": 10,
        "column": 0,
        "endLine": 10,
        "endColumn": 21,
        "path": "torchtune/modules/rlhf/loss/dpo.py",
        "symbol": "consider-using-from-import",
        "message": "Use 'from torch import nn' instead",
        "message-id": "R0402"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.dpo",
        "obj": "DPOLoss",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 13,
        "path": "torchtune/modules/rlhf/loss/dpo.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.dpo",
        "obj": "RSOLoss",
        "line": 97,
        "column": 0,
        "endLine": 97,
        "endColumn": 13,
        "path": "torchtune/modules/rlhf/loss/dpo.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.dpo",
        "obj": "IPOLoss",
        "line": 163,
        "column": 0,
        "endLine": 163,
        "endColumn": 13,
        "path": "torchtune/modules/rlhf/loss/dpo.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.rlhf.loss.dpo",
        "obj": "SimPOLoss",
        "line": 244,
        "column": 0,
        "endLine": 244,
        "endColumn": 15,
        "path": "torchtune/modules/rlhf/loss/dpo.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "error",
        "module": "torchtune.modules.rlhf.utils._convert_weights",
        "obj": "reward_hf_to_tune",
        "line": 80,
        "column": 29,
        "endLine": 80,
        "endColumn": 36,
        "path": "torchtune/modules/rlhf/utils/_convert_weights.py",
        "symbol": "possibly-used-before-assignment",
        "message": "Possibly using variable 'new_key' before assignment",
        "message-id": "E0606"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transforms._transforms",
        "obj": "Transform",
        "line": 12,
        "column": 0,
        "endLine": 12,
        "endColumn": 15,
        "path": "torchtune/modules/transforms/_transforms.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transforms._transforms",
        "obj": "VisionCrossAttentionMask",
        "line": 22,
        "column": 0,
        "endLine": 22,
        "endColumn": 30,
        "path": "torchtune/modules/transforms/_transforms.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.modules.transforms.vision_utils.get_canvas_best_fit",
        "obj": "get_canvas_best_fit",
        "line": 17,
        "column": 0,
        "endLine": 17,
        "endColumn": 23,
        "path": "torchtune/modules/transforms/vision_utils/get_canvas_best_fit.py",
        "symbol": "too-many-locals",
        "message": "Too many local variables (17/15)",
        "message-id": "R0914"
    },
    {
        "type": "warning",
        "module": "torchtune.modules.transforms.vision_utils.get_canvas_best_fit",
        "obj": "find_supported_resolutions",
        "line": 152,
        "column": 8,
        "endLine": 152,
        "endColumn": 10,
        "path": "torchtune/modules/transforms/vision_utils/get_canvas_best_fit.py",
        "symbol": "unused-variable",
        "message": "Unused variable 'ar'",
        "message-id": "W0612"
    },
    {
        "type": "warning",
        "module": "torchtune.data._chat_formats",
        "obj": "ChatFormat.format",
        "line": 44,
        "column": 8,
        "endLine": 44,
        "endColumn": 12,
        "path": "torchtune/data/_chat_formats.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._chat_formats",
        "obj": "ChatFormat",
        "line": 13,
        "column": 0,
        "endLine": 13,
        "endColumn": 16,
        "path": "torchtune/data/_chat_formats.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune.data._prompt_templates",
        "obj": "PromptTemplateInterface.__call__",
        "line": 39,
        "column": 8,
        "endLine": 39,
        "endColumn": 12,
        "path": "torchtune/data/_prompt_templates.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._prompt_templates",
        "obj": "PromptTemplateInterface",
        "line": 14,
        "column": 0,
        "endLine": 14,
        "endColumn": 29,
        "path": "torchtune/data/_prompt_templates.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._prompt_templates",
        "obj": "PromptTemplate",
        "line": 42,
        "column": 0,
        "endLine": 42,
        "endColumn": 20,
        "path": "torchtune/data/_prompt_templates.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._prompt_templates",
        "obj": "ChatMLTemplate",
        "line": 125,
        "column": 0,
        "endLine": 125,
        "endColumn": 20,
        "path": "torchtune/data/_prompt_templates.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "warning",
        "module": "torchtune.data._instruct_templates",
        "obj": "InstructTemplate.format",
        "line": 41,
        "column": 8,
        "endLine": 41,
        "endColumn": 12,
        "path": "torchtune/data/_instruct_templates.py",
        "symbol": "unnecessary-pass",
        "message": "Unnecessary pass statement",
        "message-id": "W0107"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._instruct_templates",
        "obj": "InstructTemplate",
        "line": 11,
        "column": 0,
        "endLine": 11,
        "endColumn": 22,
        "path": "torchtune/data/_instruct_templates.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._messages",
        "obj": "Message.__init__",
        "line": 53,
        "column": 4,
        "endLine": 53,
        "endColumn": 16,
        "path": "torchtune/data/_messages.py",
        "symbol": "too-many-arguments",
        "message": "Too many arguments (6/5)",
        "message-id": "R0913"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._messages",
        "obj": "InputOutputToMessages",
        "line": 119,
        "column": 0,
        "endLine": 119,
        "endColumn": 27,
        "path": "torchtune/data/_messages.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._messages",
        "obj": "ChosenRejectedToMessages",
        "line": 190,
        "column": 0,
        "endLine": 190,
        "endColumn": 30,
        "path": "torchtune/data/_messages.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._messages",
        "obj": "ShareGPTToMessages",
        "line": 287,
        "column": 0,
        "endLine": 287,
        "endColumn": 24,
        "path": "torchtune/data/_messages.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._messages",
        "obj": "JSONToMessages",
        "line": 378,
        "column": 0,
        "endLine": 378,
        "endColumn": 20,
        "path": "torchtune/data/_messages.py",
        "symbol": "too-few-public-methods",
        "message": "Too few public methods (1/2)",
        "message-id": "R0903"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules -> torchtune.modules.transformer)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules.peft -> torchtune.modules.peft.dora)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.training -> torchtune.training.checkpointing -> torchtune.training.checkpointing._checkpointer)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules.peft -> torchtune.modules.peft.lora)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.training -> torchtune.training._profiler)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules -> torchtune.modules.vision_transformer)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules -> torchtune.modules.vision_transformer -> torchtune.modules.transformer)",
        "message-id": "R0401"
    },
    {
        "type": "refactor",
        "module": "torchtune.data._utils",
        "obj": "",
        "line": 1,
        "column": 0,
        "endLine": null,
        "endColumn": null,
        "path": "torchtune/data/_utils.py",
        "symbol": "cyclic-import",
        "message": "Cyclic import (torchtune.modules.rlhf -> torchtune.modules.rlhf.sequence_processing)",
        "message-id": "R0401"
    }
]
